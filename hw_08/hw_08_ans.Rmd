---
title: "Eighth Week: Text Analysis in R"
subtitle: "To be, or not to be"
author: "Ali Mohammad Faraji"
date: "`r Sys.time()`"
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
---

<div align="center">
<img  src="images/dickens1_1.png"  align = 'center'>
</div>


<p dir="LTR">
```{r}
library(tidytext)
library(gutenbergr)
library(tm)
library(dplyr)
library(stringr)
library(highcharter)
library(yaml)
library(wordcloud2)
library(ngram)
library(tidyr)
library(wordcloud)
```

</p>

***

<p dir="LTR">
1.
```{r}
ThePickwickPapers = gutenberg_download(580)
OliverTwist = gutenberg_download(730)
NicholasNickleby = gutenberg_download(967)
TheOldCuriosityShop = gutenberg_download(700)
BarnabyRudge = gutenberg_download(917)
MartinChuzzlewit = gutenberg_download(968)
DombeyandSon = gutenberg_download(821)
DavidCopperfield =gutenberg_download(766)
BleakHouse =gutenberg_download(1023)
HardTimes =gutenberg_download(786)
LittleDorrit =gutenberg_download(963)
ATaleofTwoCities = gutenberg_download(98)
GreatExpectations = gutenberg_download(1400)
OurMutualFriend = gutenberg_download(883)
TheMysteryofEdwinDrood =gutenberg_download(564)

all_Dickens_Novels = ThePickwickPapers$text
all_Dickens_Novels = list(ThePickwickPapers$text, OliverTwist$text, NicholasNickleby$text, TheOldCuriosityShop$text, 
                       BarnabyRudge$text, MartinChuzzlewit$text, DombeyandSon$text, DavidCopperfield$text, BleakHouse$text, HardTimes$text, LittleDorrit$text, ATaleofTwoCities$text, GreatExpectations$text, OurMutualFriend$text, TheMysteryofEdwinDrood$text)

str(all_Dickens_Novels)
```
```{r}
#View(all_Dickens_Novels)
 all_Dickens_Novels %>% 
    str_replace_all("\"","") %>% 
    str_replace_all("[[:punct:]]","") %>% 
    str_split(pattern = "\\s") -> Dick_nov_per_nov

Dick_nov_per_nov %>% unlist() %>% 
    table() %>% 
    as.data.frame(stringsAsFactors = F) -> all_Dickens_Novels_normalized
  colnames(all_Dickens_Novels_normalized) = c("word","count")
  all_Dickens_Novels_normalized = all_Dickens_Novels_normalized %>%
    filter(!str_to_lower(word) %in% stopwords()) %>% 
    filter(str_length(word)>1) %>% 
    filter(!str_detect(word,"\\d")) %>%
    arrange(desc(count))
View(all_Dickens_Novels_normalized)

all_Dickens_Novels_normalized

head(all_Dickens_Novels_normalized, 20) %>% hchart("column", hcaes(x = word, y = count)) %>% hc_add_theme(hc_theme_monokai())

```

```{r}

```

</p>

***

<p dir="LTR">
```{r}
all_Dickens_Novels_normalized
wordcloud2(data = head(all_Dickens_Novels_normalized, 200), size = 0.5)
           
```


***

<p dir="LTR">
3.
```{r}
#characters = list(c("samuel", "nathaniel", "augustus", "tracy", "sam"), 
 #                 c("twist", "bumble", "mann", "sowerberry", "noah"),
  #                c("nicholas", "ralph", "kate", "catherine", "smike", "newman"),
                  
   #               )

all_names_freqs = data.frame("number" = c(), "one" = c(), "two"= c(), "three" = c(), "four" = c(), "five" = c(), "freq" = c())
str(Dick_nov_per_nov)
for (i in 1:15){
  tmp = str_match(unlist(Dick_nov_per_nov[i]), "^[:upper:][:alpha:]+")
  tmp
  tmp = table(tmp) %>% as.data.frame(stringsAsFactors = F)
  tmp
  replacee =  tmp %>% filter(! str_to_lower(tmp) %in% stop_words$word) %>% filter(! str_to_lower(tmp) %in% c("mr", "miss", "sir", "mrs", "the", "it", "he", "she")) %>% arrange(-Freq) %>% slice(1:5) %>%  as.vector()
  replacee = cbind(rep(i, 5), replacee)
  all_names_freqs = rbind(all_names_freqs, replacee)
}
#View(all_names_freqs)
all_names_freqs %>% hchart("column", hcaes(x = tmp, y = Freq, group = `rep(i, 5)`))
```

</p>

***

<p dir="LTR">
4.
```{r}
positives = sentiments %>% filter(sentiment == "positive") %>% .$word
negatives = sentiments %>% filter(sentiment == "negative") %>% .$word
sentimentals = data.frame("Pos" = c() ,"Story" = c(), "Word" = c(), "freq" = c())
for (i in 1:15){
  tmp = Dick_nov_per_nov[i]
  tmPos = table(tmp) %>% as.data.frame(stringsAsFactors = F) %>% filter(str_to_lower(tmp) %in% positives) %>% arrange(-Freq) %>% slice(1:20)
  tmPos
  tmNeg = table(tmp) %>% as.data.frame(stringsAsFactors = F) %>% filter(str_to_lower(tmp) %in% negatives) %>% arrange(-Freq) %>% slice(1:20)
  
  t = data.frame(cbind(rep("P", 20), rep(i, 20), tmPos))
  names(t) = c("Pos", "Story", "Word", "freq")
  
  sentimentals = rbind(sentimentals, t)
  
  t = data.frame(cbind(rep("N", 20), rep(i, 20), tmNeg))
  names(t) = c("Pos", "Story", "Word", "freq")
   sentimentals = rbind(sentimentals, t)
}


  hchart(sentimentals %>% filter(Story == 1), "column", hcaes(x = Word, y = freq, group = Pos))
  hchart(sentimentals %>% filter(Story == 2), "column", hcaes(x = Word, y = freq, group = Pos))
  hchart(sentimentals %>% filter(Story == 3), "column", hcaes(x = Word, y = freq, group = Pos))
  hchart(sentimentals %>% filter(Story == 4), "column", hcaes(x = Word, y = freq, group = Pos))
  hchart(sentimentals %>% filter(Story == 5), "column", hcaes(x = Word, y = freq, group = Pos))
  hchart(sentimentals %>% filter(Story == 6), "column", hcaes(x = Word, y = freq, group = Pos))
  hchart(sentimentals %>% filter(Story == 7), "column", hcaes(x = Word, y = freq, group = Pos))
  hchart(sentimentals %>% filter(Story == 8), "column", hcaes(x = Word, y = freq, group = Pos))
  hchart(sentimentals %>% filter(Story == 9), "column", hcaes(x = Word, y = freq, group = Pos))
  hchart(sentimentals %>% filter(Story == 10), "column", hcaes(x = Word, y = freq, group = Pos))

hchart(sentimentals %>% filter(Story == 11), "column", hcaes(x = Word, y = freq, group = Pos))
hchart(sentimentals %>% filter(Story == 12), "column", hcaes(x = Word, y = freq, group = Pos))
hchart(sentimentals %>% filter(Story == 13), "column", hcaes(x = Word, y = freq, group = Pos))
hchart(sentimentals %>% filter(Story == 14), "column", hcaes(x = Word, y = freq, group = Pos))
hchart(sentimentals %>% filter(Story == 15), "column", hcaes(x = Word, y = freq, group = Pos))
```
It is different for different stories.  For example, on the first story, the positive words are more frequent and thus we can conclude it may have a more positive atmosphere. On the other hand, 14th and 15th stories are more neutral. 
</div>

***

<p dir="LTR">
5.
```{r}
LesMiserables = gutenberg_download(135)
LesMiserablesText = LesMiserables$text
 LesMiserablesText %>% 
    str_replace_all("\"","") %>% 
    str_replace_all("[[:punct:]]","") %>% 
    str_split(pattern = "\\s") %>% unlist() %>% str_to_lower()-> LesMiserablesText
 
 str(LesMiserablesText)
 
 m = matrix(LesMiserablesText, byrow = T, nrow = 200)

sum(LesMiserablesText %in% positives)
sum(LesMiserablesText %in% negatives)
m = data.frame(m, stringsAsFactors = FALSE)
m %>% mutate(numRow = 1:n()) %>% rowwise() %>% mutate(pos = sum(m[numRow,] %in% c(positives)), neg = sum(m[numRow,] %in% c(negatives))) %>% select(numRow, pos, neg) -> m

m = m %>% gather(sentiment, freq, pos:neg)
m %>% hchart("line", hcaes(x = numRow, y = freq, group = sentiment))
```

</p>

***

<p dir="LTR">
6.
```{r}
LesMiserablesText = LesMiserables$text
 LesMiserablesText %>% 
    str_replace_all("\"","") %>% 
    str_replace_all("[[:punct:]]","") %>% 
    str_split(pattern = "\\s") %>% unlist() %>% str_to_lower()-> LesMiserablesText
 str(LesMiserablesText)
 LesMiserablesTextt = str_c(LesMiserablesText, collapse = " ")
str(LesMiserablesTextt)
ngram(LesMiserablesTextt, n = 2) -> twoGramObj
twoGramObj %>% get.phrasetable() -> phTable
phTable %>% arrange(-freq) %>% slice(1:30) %>% select(ngrams, freq) %>% hchart("column", hcaes(x = ngrams, y = freq))
```

</p>

***

<p dir="LTR">
7.
```{r}
phTable %>% filter(str_detect(ngrams, "^(he |she )+")) -> heSheVerb

heSheVerb %>% mutate(verb = str_replace_all(ngrams, "^(he |she )", "")) %>% group_by(verb) %>% summarise(freq = sum(freq)) %>% arrange(-freq) %>% slice(1:20) %>% hchart("column", hcaes(x = verb, y = freq))
```

</p>

***

<p dir="LTR">
8.
```{r}
str(all_Dickens_Novels)
 all_Dickens_Novels %>% 
    str_replace_all("\"","") %>% 
    str_replace_all("[[:punct:]]","") %>% 
    str_split(pattern = "\\s") -> all_Dickens_Novels_text
 str(all_Dickens_Novels_text)
 first_book = all_Dickens_Novels_text[1] %>% unlist() %>% str_c(collapse = " ")
 first_book_spitted = first_book %>% str_split_fixed("CHAPTER", n = Inf)
 first_book
#str(first_book_spitted)
#View(first_book_spitted)
for (i in 20:119){ if (str_length(first_book_spitted[1, i]) >= 500){
  ngram(first_book_spitted[1, i], n = 1) -> obj
obj %>% get.phrasetable() -> twoGramI
plot(density(twoGramI$freq))
}}
for (i in 20:119){ if (str_length(first_book_spitted[1, i]) >= 500){
  ngram(first_book_spitted[1, i], n = 2) -> obj
obj %>% get.phrasetable() -> twoGramI
plot(density(twoGramI$freq))
}}
```
We plot the desity function for each chapter of the first book. It is easy to plot them for other books too. But due to the heavy volume it takes, we just plot the 1-gram and 2-gram density functions for the whole curpus.
```{r}
 all_corpus_Dickens = all_Dickens_Novels_text[2:4] %>% unlist() %>% str_c(collapse = " ")%>% str_c(collapse = " ")
str(all_corpus_Dickens)
 ngram(all_corpus_Dickens, n = 1) -> obj
obj %>% get.phrasetable() -> twoGramI
plot(density(twoGramI$freq))
 ngram(all_corpus_Dickens, n = 2) -> obj
obj %>% get.phrasetable() -> twoGramI
plot(density(twoGramI$freq))
```

</p>

***
<p dir="LTR">
9.
```{r}

Persuasion = gutenberg_download(105)
Northanger = gutenberg_download(121)
Mansfield = gutenberg_download(141)
Emma = gutenberg_download(158)
Sense = gutenberg_download(161)
Pride = gutenberg_download(1342)

austin_novs = list(Persuasion$text, Northanger$text, Mansfield$text, Emma$text, 
                       Sense$text, Pride$text)
 austin_novs %>% 
    str_replace_all("\"","") %>% 
    str_replace_all("[[:punct:]]","") %>% 
    str_split(pattern = "\\s") -> austin_nov_per_nov
 
  all_austin = austin_nov_per_nov %>% unlist() %>% str_c(collapse = " ")
str(all_austin)
 ngram(all_austin, n = 1) -> obj
obj %>% get.phrasetable() -> twoGramI
plot(density(twoGramI$freq))
 ngram(all_austin, n = 2) -> obj
obj %>% get.phrasetable() -> twoGramI
plot(density(twoGramI$freq))


```
As we can see, the plots are similar. 
</p>

***


